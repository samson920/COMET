{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.stats import pearsonr\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "import random\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load CSV files which are direct extracts from OMOP tables\n",
    "conds = pd.read_csv('./data/raw_data/EHR/EHR_cohort_conditions.csv').drop('Unnamed: 0', axis=1)\n",
    "conds = conds[conds['condition_concept_id'] != 0]\n",
    "drugs = pd.read_csv('./data/raw_data/EHR/EHR_cohort_drugs.csv').drop('Unnamed: 0', axis=1)\n",
    "drugs = drugs[drugs['drug_concept_id'] != 0]\n",
    "procs = pd.read_csv('./data/raw_data/EHR/EHR_cohort_procedures.csv').drop('Unnamed: 0', axis=1)\n",
    "procs = procs[procs['procedure_concept_id'] != 0]\n",
    "obs = pd.read_csv('./data/raw_data/EHR/EHR_cohort_observations.csv').drop('Unnamed: 0', axis=1)\n",
    "obs = obs[obs['observation_concept_id'] != 0]\n",
    "\n",
    "conds['condition_start_DATETIME'] = pd.to_datetime(conds['condition_start_DATETIME'])\n",
    "procs['procedure_DATETIME'] = pd.to_datetime(procs['procedure_DATETIME'])\n",
    "drugs['drug_exposure_start_DATETIME'] = pd.to_datetime(drugs['drug_exposure_start_DATETIME'])\n",
    "obs['observation_DATETIME'] = pd.to_datetime(obs['observation_DATETIME'])\n",
    "\n",
    "conds['child_birth_date'] = pd.to_datetime(conds['child_birth_date'])\n",
    "procs['child_birth_date'] = pd.to_datetime(procs['child_birth_date'])\n",
    "drugs['child_birth_date'] = pd.to_datetime(drugs['child_birth_date'])\n",
    "obs['child_birth_date'] = pd.to_datetime(obs['child_birth_date'])\n",
    "\n",
    "measurements = pd.read_csv('./data/raw_data/EHR/EHR_cohort_measurements.csv').drop('Unnamed: 0', axis=1)\n",
    "measurements = measurements[~pd.isnull(measurements['value_as_number'])]\n",
    "measurements = measurements[measurements['measurement_concept_id'] != 0]\n",
    "measurements['measurement_DATETIME'] = pd.to_datetime(measurements['measurement_DATETIME'])\n",
    "measurements['child_birth_date'] = pd.to_datetime(measurements['child_birth_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load IDs of mothers in omics cohort\n",
    "OOL_cohort_omop = pd.read_csv('./data/ool_EHR_features.csv')['mom_person_id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter data to only mothers in omics cohort\n",
    "conds = conds[conds['mom_person_id'].isin(OOL_cohort_omop)]\n",
    "drugs = drugs[drugs['mom_person_id'].isin(OOL_cohort_omop)]\n",
    "procs = procs[procs['mom_person_id'].isin(OOL_cohort_omop)]\n",
    "measurements = measurements[measurements['mom_person_id'].isin(OOL_cohort_omop)]\n",
    "obs = obs[obs['mom_person_id'].isin(OOL_cohort_omop)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load OMOP concept table for easier interpretability\n",
    "concepts = pd.read_csv('../cancer/data/raw_data/EHR/concepts.csv').drop('Unnamed: 0',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label drugs with their name\n",
    "drugs = drugs.merge(concepts, how='left', left_on='drug_concept_id', right_on='concept_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_df(df, birth_time, time_col, time_range_days=280):\n",
    "    \"\"\"\n",
    "    A function to remove entries in a dataframe prior to time of birth. \n",
    "    \n",
    "    df: The dataframe to filter. Must contain a column called person_id with the OMOP ID of the mother\n",
    "    birth_time: A dataframe that contains two columns: maternal_OMOP and birth_DATETIME\n",
    "    time_col: The index of the column with the date of the event in df\n",
    "    time_range_days: keeps data from delivery up to time_range_days prior \n",
    "    \n",
    "    \"\"\"\n",
    "    print('There were {} patients before filtering.'.format(len(df['person_id'].unique())))\n",
    "    df = df.merge(birth_time, how='inner', left_on='person_id', right_on='maternal_OMOP')\n",
    "    df['diff'] = df['birth_DATETIME']-df[time_col]\n",
    "    new_df = df[(df['diff'].dt.days > 0) & (df['diff'].dt.days <= time_range_days)].drop('maternal_OMOP', axis=1)\n",
    "    print('There were {} patients after filtering.'.format(len(new_df['person_id'].unique())))\n",
    "    return new_df\n",
    "\n",
    "def generate_features_EHR_cohort(proteomics, input_df, time_col_name, concept_id_col, indicator, binary=True):\n",
    "    df = proteomics[['DOS','mom_person_id','child_person_id','sample_ID']].merge(input_df, how='left', on=['mom_person_id','child_person_id'])\n",
    "    df['delta'] = (df[time_col_name]-df['child_birth_date']).dt.days\n",
    "    df = df[df['delta'] < df['DOS']]\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load key file which can be used to map proteomics data to mother person_id\n",
    "patient_indices = pd.read_csv('./data/processed_data/sampleID_indices.csv').drop('Unnamed: 0',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load and clean proteomics data\n",
    "OOL_proteomics = pd.read_csv('./data/processed_data/ool_proteomics_omop_id.csv').drop(['Unnamed: 0','SampleID','ID','EGA'],axis=1)\n",
    "OOL_proteomics['sample_ID'] = OOL_proteomics['maternal_person_id'].astype(str)+'_'+OOL_proteomics['Timepoint'].astype(str)\n",
    "OOL_proteomics = OOL_proteomics.drop(['Timepoint','maternal_person_id'],axis=1)\n",
    "OOL_proteomics.columns = [str(i)+'_protein' for i in OOL_proteomics.columns]\n",
    "OOL_proteomics = OOL_proteomics.rename(columns={'DOS_protein':'DOS_sampling_time', 'sample_ID_protein':'sample_ID'})\n",
    "OOL_proteomics = OOL_proteomics[['sample_ID','DOS_sampling_time']]\n",
    "OOL_proteomics['mom_person_id'] = OOL_proteomics['sample_ID'].str[0:7].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This block of code creates a dataframe with mom_person_id, child_person_id, min_delta, max_delta \n",
    "## (based on the range of EHR data available), days to onset, and a combined sample_ID col which is used as an identifier\n",
    "\n",
    "# Filter and calculate delta\n",
    "time_col_name = 'condition_start_DATETIME'\n",
    "df = conds\n",
    "df['delta'] = (df[time_col_name] - df['child_birth_date']).dt.days\n",
    "\n",
    "# Calculate min and max delta in one operation\n",
    "ool = df.groupby(['mom_person_id', 'child_person_id'])['delta'].agg(['min', 'max'])\n",
    "ool.columns = ['min_delta', 'max_delta']\n",
    "\n",
    "# Filter for samples with at least 7 days between min and max\n",
    "sampling_df = ool[ool['max_delta'] - ool['min_delta'] >= 7].reset_index()\n",
    "\n",
    "# Create initial sample_ID\n",
    "sampling_df['sample_ID'] = sampling_df['mom_person_id'].astype(str) + '_' + sampling_df['child_person_id'].astype(str)\n",
    "\n",
    "# Filter based on OOL_sample_IDs\n",
    "OOL_sample_IDs = np.unique([i[0:15] for i in list(patient_indices['0'])])\n",
    "sampling_df = sampling_df[sampling_df['sample_ID'].str[:15].isin(OOL_sample_IDs)]\n",
    "\n",
    "# Merge with OOL_proteomics\n",
    "sampling_df = sampling_df.merge(OOL_proteomics, how='inner', on='mom_person_id', suffixes=('_x', '_y'))\n",
    "\n",
    "# Set DOS\n",
    "sampling_df['DOS'] = sampling_df['DOS_sampling_time']\n",
    "\n",
    "# Create the correct sample_ID\n",
    "sampling_df['sample_ID'] = sampling_df['sample_ID_x'] + sampling_df['sample_ID_y'].str[-3:]\n",
    "\n",
    "# Drop unnecessary columns\n",
    "columns_to_drop = ['sample_ID_x', 'sample_ID_y', 'DOS_sampling_time']\n",
    "sampling_df = sampling_df.drop(columns_to_drop, axis=1, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter data so it only occurs within the correct time range (beginning of pregnancy thru sampling)\n",
    "condition_features_EHR = generate_features_EHR_cohort(sampling_df, conds, 'condition_start_DATETIME','condition_concept_id','C')\n",
    "procedure_features_EHR = generate_features_EHR_cohort(sampling_df, procs, 'procedure_DATETIME','procedure_concept_id','P')\n",
    "drug_features_EHR = generate_features_EHR_cohort(sampling_df, drugs, 'drug_exposure_start_DATETIME','drug_concept_id','D')\n",
    "measurement_features_EHR = generate_features_EHR_cohort(sampling_df, measurements, 'measurement_DATETIME','measurement_concept_id','M')\n",
    "observation_features_EHR = generate_features_EHR_cohort(sampling_df, obs, 'observation_DATETIME','observation_concept_id','O')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EpochLogger(CallbackAny2Vec):\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "\n",
    "    def on_epoch_begin(self, model):\n",
    "        print(f\"Starting epoch #{self.epoch}\")\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        print(f\"Finished epoch #{self.epoch}\")\n",
    "        self.epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train word2vec model\n",
    "# NOTE: For word2vec model training, we do NOT do the date filtering and use all data from pregnancy\n",
    "try:\n",
    "    model = Word2Vec.load(\"./models/word2vec_OOL_cohort_measurements_observations_full_pregnancy_sampling_400dim.model\")\n",
    "    #model = Word2Vec.load(\"./models/word2vec/word2vec_full_pregnancy_cohort_measurements_observations_full_pregnancy_sampling_400dim.model\")\n",
    "except:\n",
    "    \n",
    "    epoch_logger = EpochLogger()\n",
    "\n",
    "    word2vec_conds = condition_features_EHR[['sample_ID','condition_concept_id','condition_start_DATETIME']]\n",
    "    word2vec_conds.columns = ['sample_ID','concept_id','ts']\n",
    "\n",
    "    word2vec_procs = procedure_features_EHR[['sample_ID','procedure_concept_id','procedure_DATETIME']]\n",
    "    word2vec_procs.columns = ['sample_ID','concept_id','ts']\n",
    "\n",
    "    word2vec_drug = drug_features_EHR[['sample_ID','drug_concept_id','drug_exposure_start_DATETIME']]\n",
    "    word2vec_drug.columns = ['sample_ID','concept_id','ts']\n",
    "    \n",
    "    word2vec_mea = measurement_features_EHR[['sample_ID','measurement_concept_id','measurement_DATETIME']]\n",
    "    word2vec_mea.columns = ['sample_ID','concept_id','ts']\n",
    "    \n",
    "    word2vec_obs = observation_features_EHR[['sample_ID','observation_concept_id','observation_DATETIME']]\n",
    "    word2vec_obs.columns = ['sample_ID','concept_id','ts']\n",
    "    \n",
    "    word2vec_data = pd.concat([word2vec_conds, word2vec_procs, word2vec_drug,word2vec_mea, word2vec_obs],axis=0)\n",
    "    word2vec_data['date'] = pd.to_datetime(word2vec_data['ts'])\n",
    "    word2vec_data['date'] = word2vec_data['date'].dt.date\n",
    "    word2vec_data = word2vec_data.drop('ts',axis=1)\n",
    "    word2vec_data = word2vec_data[~pd.isnull(word2vec_data['concept_id'])]\n",
    "    word2vec_data['concept_id'] = word2vec_data['concept_id'].astype(int)\n",
    "    \n",
    "    grouped_data = word2vec_data.groupby(['sample_ID', 'date'])\n",
    "    sentences = []\n",
    "    for _, group in tqdm(grouped_data):\n",
    "        codes = group['concept_id'].tolist()\n",
    "        random.shuffle(codes)\n",
    "        sentences.append(codes)\n",
    "        \n",
    "    print('starting training')\n",
    "    model = Word2Vec(sentences, vector_size=400, window=1000, min_count=5, workers=64)\n",
    "    model.train(sentences, total_examples=len(sentences), epochs=20, callbacks=[epoch_logger])\n",
    "    model.save(\"./models/word2vec_OOL_cohort_measurements_observations_full_pregnancy_sampling_400dim.model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_to_embedding = {code: model.wv[code] for code in model.wv.index_to_key}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#map EHR data to their respective learned embeddings from word2vec\n",
    "embedded_conds = condition_features_EHR[(condition_features_EHR['condition_concept_id'] != 0)]\n",
    "embedded_conds = embedded_conds[~pd.isnull(embedded_conds['condition_concept_id'])]\n",
    "embedded_conds['embedding'] = [code_to_embedding.get(code) for code in embedded_conds['condition_concept_id']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_procs = procedure_features_EHR[(procedure_features_EHR['procedure_concept_id'] != 0)]\n",
    "embedded_procs = embedded_procs[~pd.isnull(embedded_procs['procedure_concept_id'])]\n",
    "embedded_procs['embedding'] = [code_to_embedding.get(code) for code in embedded_procs['procedure_concept_id']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_drugs = drug_features_EHR[(drug_features_EHR['drug_concept_id'] != 0)]\n",
    "embedded_drugs = embedded_drugs[~pd.isnull(embedded_drugs['drug_concept_id'])]\n",
    "embedded_drugs['embedding'] = [code_to_embedding.get(code) for code in embedded_drugs['drug_concept_id']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_measurements = measurement_features_EHR[(measurement_features_EHR['measurement_concept_id'] != 0)]\n",
    "embedded_measurements = embedded_measurements[~pd.isnull(embedded_measurements['measurement_concept_id'])]\n",
    "embedded_measurements['embedding'] = [code_to_embedding.get(code) for code in embedded_measurements['measurement_concept_id']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_obs = observation_features_EHR[(observation_features_EHR['observation_concept_id'] != 0)]\n",
    "embedded_obs = embedded_obs[~pd.isnull(embedded_obs['observation_concept_id'])]\n",
    "embedded_obs['embedding'] = [code_to_embedding.get(code) for code in embedded_obs['observation_concept_id']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_procs['date'] = pd.to_datetime(embedded_procs['procedure_DATETIME'].dt.date)\n",
    "embedded_conds['date'] = pd.to_datetime(embedded_conds['condition_start_DATETIME'].dt.date)\n",
    "embedded_drugs['date'] = pd.to_datetime(embedded_drugs['drug_exposure_start_DATETIME'].dt.date)\n",
    "embedded_measurements['date'] = pd.to_datetime(embedded_measurements['measurement_DATETIME'].dt.date)\n",
    "embedded_obs['date'] = pd.to_datetime(embedded_obs['observation_DATETIME'].dt.date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#combine all EHR data tables together\n",
    "embedded_conds = embedded_conds[~pd.isnull(embedded_conds['embedding'])]\n",
    "embedded_procs = embedded_procs[~pd.isnull(embedded_procs['embedding'])]\n",
    "embedded_drugs = embedded_drugs[~pd.isnull(embedded_drugs['embedding'])]\n",
    "embedded_measurements = embedded_measurements[~pd.isnull(embedded_measurements['embedding'])]\n",
    "embedded_obs = embedded_obs[~pd.isnull(embedded_obs['embedding'])]\n",
    "\n",
    "all_data = pd.concat([embedded_conds.drop(['DOS','mom_person_id','child_person_id', 'condition_concept_id',\n",
    "                      'condition_start_DATETIME','child_birth_date','delta',\n",
    "                                'condition_source_value'],axis=1),\n",
    "    embedded_procs.drop(['DOS','mom_person_id','child_person_id','person_id', 'procedure_concept_id',\n",
    "                        'procedure_DATETIME','child_birth_date','delta'],axis=1),\n",
    "     embedded_drugs.drop(['DOS','mom_person_id','child_person_id', 'drug_concept_id',\n",
    "                        'drug_exposure_start_DATETIME','child_birth_date','delta'],axis=1),\n",
    "     embedded_measurements.drop(['DOS','mom_person_id','child_person_id', 'measurement_concept_id',\n",
    "                        'measurement_DATETIME','value_as_number','child_birth_date','delta'],axis=1),\n",
    "    embedded_obs.drop(['DOS','mom_person_id','child_person_id', 'observation_concept_id',\n",
    "                        'observation_DATETIME','child_birth_date','delta'],axis=1)], ignore_index=True)[['sample_ID','date','embedding']]\n",
    "\n",
    "expanded_embedding_df = pd.DataFrame(all_data['embedding'].tolist())\n",
    "print('done making interim dataframe')\n",
    "all_data = pd.concat([all_data.reset_index(drop=True).drop('embedding',axis=1), expanded_embedding_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#take the mean to compute patient-day embeddings\n",
    "patient_day_embeddings = all_data.groupby(['sample_ID','date']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_day_embeddings = patient_day_embeddings.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_day_embeddings['date'] = pd.to_datetime(patient_day_embeddings['date'])\n",
    "patient_day_embeddings = patient_day_embeddings.sort_values(['sample_ID', 'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_patients = patient_day_embeddings['sample_ID'].nunique()\n",
    "num_features = len(patient_day_embeddings.columns) - 2  # Subtract patient_id and date columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_dates = patient_day_embeddings.groupby('sample_ID')['date'].count().max()\n",
    "max_dates = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign each patient id to an index in the input data matrix\n",
    "patient_id_to_index = {patient_id: index for index, patient_id in enumerate(patient_day_embeddings['sample_ID'].unique())}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create input data matrix\n",
    "RNN_data = np.full((num_features, max_dates, unique_patients), np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#fill in input data matrix with person-day EHR data embeddings\n",
    "date_position = {}\n",
    "for index, row in tqdm(patient_day_embeddings.iterrows()):\n",
    "    patient_id = row['sample_ID']\n",
    "    patient_index = patient_id_to_index[patient_id]\n",
    "    \n",
    "    if patient_id not in date_position:\n",
    "        date_position[patient_id] = 0\n",
    "    else:\n",
    "        date_position[patient_id] += 1\n",
    "        \n",
    "    date_index = date_position[patient_id]\n",
    "    \n",
    "    for feature_index, feature_value in enumerate(row.drop(['sample_ID', 'date'])):\n",
    "        if date_index < max_dates:\n",
    "            RNN_data[feature_index, date_index, patient_index] = feature_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN_data = RNN_data.transpose(2,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#align outcome data with correct index\n",
    "sampling_df = sampling_df.merge(pd.DataFrame([patient_id_to_index.keys(), patient_id_to_index.values()]).T, how='right', left_on='sample_ID', right_on=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#align outcome data with correct index\n",
    "sampling_df = sampling_df.merge(patient_day_embeddings.groupby('sample_ID').count()[['date']], how='left', on='sample_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOS_outcomes = np.array(sampling_df[['DOS',1]].sort_values(1)['DOS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN_data.shape, DOS_outcomes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save processed data below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./data/processed_data/RNN_data_codes_with_obs_word2vec_from_ool.npy', RNN_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./data/processed_data/RNN_data_outcomes_with_obs_word2vec_from_ool.npy', DOS_outcomes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_outcomes = torch.tensor(DOS_outcomes).float()\n",
    "num_patient_visits = np.minimum(np.array(sampling_df['date']), 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./data/processed_data/RNN_data_lengths_with_obs_word2vec_from_ool.npy', num_patient_visits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([list(patient_id_to_index.keys()),list(patient_id_to_index.values())]).T.to_csv('./data/processed_data/sampleID_indices_with_obs_word2vec_from_ool.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
