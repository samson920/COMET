{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import dxpy\n",
    "import dxdata\n",
    "import pandas as pd\n",
    "import random\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import Word2Vec\n",
    "from pyspark.sql.functions import col, udf, to_date, mean, expr, concat_ws\n",
    "from pyspark.sql.types import StringType, ArrayType, IntegerType, DoubleType\n",
    "from pyspark.ml.feature import Word2Vec\n",
    "from pyspark.sql.window import Window\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sc = pyspark.SparkContext()\n",
    "spark = pyspark.sql.SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dispensed_database_name = dxpy.find_one_data_object(classname=\"database\", name=\"app*\", folder=\"/\", name_mode=\"glob\", describe=True)[\"describe\"][\"name\"]\n",
    "dispensed_dataset_id = dxpy.find_one_data_object(typename=\"Dataset\", name=\"app*.dataset\", folder=\"/\", name_mode=\"glob\")[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.sql(\"USE \" + dispensed_database_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec Omics Cohort "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "combined_query = spark.sql(\"\"\"\n",
    "WITH EarliestCConds AS (\n",
    "    SELECT \n",
    "        c.eid,\n",
    "        MIN(TO_DATE(c.condition_start_date, 'dd/MM/yyyy')) as earliest_cond_date\n",
    "    FROM \n",
    "        omop_condition_occurrence c\n",
    "    INNER JOIN \n",
    "        olink_instance_0_0001 o ON c.eid = o.eid\n",
    "    WHERE \n",
    "        c.condition_source_value LIKE 'C%'\n",
    "    GROUP BY \n",
    "        c.eid\n",
    "),\n",
    "FilteredPatients AS (\n",
    "    SELECT \n",
    "        ecc.eid,\n",
    "        ecc.earliest_cond_date,\n",
    "        TO_DATE(p.p53_i0, 'yyyy-MM-dd') AS proteomics_date \n",
    "    FROM \n",
    "        EarliestCConds ecc\n",
    "    INNER JOIN \n",
    "        participant_0001 p ON ecc.eid = p.eid\n",
    "    WHERE \n",
    "        ecc.earliest_cond_date < TO_DATE(p.p53_i0, 'yyyy-MM-dd')\n",
    "        AND ecc.earliest_cond_date >= ADD_MONTHS(TO_DATE(p.p53_i0, 'yyyy-MM-dd'), -12)\n",
    ")\n",
    "\n",
    "SELECT \n",
    "    fp.eid, \n",
    "    c.concept_id, \n",
    "    c.record_date,\n",
    "    DATE_FORMAT(c.record_date, 'yyyy-MM-dd') as formatted_date\n",
    "FROM \n",
    "    FilteredPatients fp\n",
    "JOIN (\n",
    "    SELECT \n",
    "        o.eid, \n",
    "        o.condition_concept_id as concept_id, \n",
    "        TO_DATE(o.condition_start_date, 'dd/MM/yyyy') as record_date\n",
    "    FROM \n",
    "        omop_condition_occurrence o\n",
    "    UNION ALL\n",
    "    SELECT \n",
    "        o.eid, \n",
    "        o.procedure_concept_id as concept_id, \n",
    "        TO_DATE(o.procedure_date, 'dd/MM/yyyy') as record_date\n",
    "    FROM \n",
    "        omop_procedure_occurrence o\n",
    "    UNION ALL\n",
    "    SELECT \n",
    "        o.eid, \n",
    "        o.drug_concept_id as concept_id, \n",
    "        TO_DATE(o.drug_exposure_start_date, 'dd/MM/yyyy') as record_date\n",
    "    FROM \n",
    "        omop_drug_exposure o\n",
    "    UNION ALL\n",
    "    SELECT \n",
    "        o.eid, \n",
    "        o.observation_concept_id as concept_id, \n",
    "        TO_DATE(o.observation_date, 'dd/MM/yyyy') as record_date\n",
    "    FROM \n",
    "        omop_observation o\n",
    "    UNION ALL\n",
    "    SELECT \n",
    "        o.eid, \n",
    "        o.measurement_concept_id as concept_id, \n",
    "        TO_DATE(o.measurement_date, 'dd/MM/yyyy') as record_date\n",
    "    FROM \n",
    "        omop_measurement o\n",
    ") c ON fp.eid = c.eid\n",
    "\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "distinct_eids = combined_query.select(\"eid\").distinct()\n",
    "num_distinct_eids = distinct_eids.count()\n",
    "\n",
    "print(f\"Number of distinct eids: {num_distinct_eids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "combined_query.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Count the number of rows in the result\n",
    "row_count = combined_query.count()\n",
    "\n",
    "# Print the row count\n",
    "print(f\"Number of rows in the query result: {row_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder.appName(\"Word2Vec Training\").getOrCreate()\n",
    "\n",
    "combined_query = combined_query.withColumn(\"concept_id\", combined_query[\"concept_id\"].cast(IntegerType()))\n",
    "\n",
    "# Group by 'eid' (person_id) and 'month_year'\n",
    "grouped_data = (combined_query.groupBy(\"eid\", \"formatted_date\")\n",
    "                .agg(F.collect_list(\"concept_id\").alias(\"concept_ids\")))\n",
    "\n",
    "# Define a UDF to convert integers to strings\n",
    "int_to_string_udf = udf(lambda x: [str(i) for i in x], ArrayType(StringType()))\n",
    "\n",
    "# Apply the UDF to the 'concept_ids' column\n",
    "word2Vec_data = grouped_data.withColumn(\"words\", int_to_string_udf(col(\"concept_ids\")))\n",
    "\n",
    "# Define the Word2Vec model\n",
    "print('started training')\n",
    "word2vec = Word2Vec(vectorSize=400, windowSize=100, minCount=5, inputCol=\"words\", outputCol=\"wordVectors\").setMaxIter(3)\n",
    "\n",
    "# Fit the model\n",
    "model = word2vec.fit(word2Vec_data)\n",
    "print('done training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "word_vectors = model.getVectors()\n",
    "\n",
    "pandas_df = word_vectors.toPandas()\n",
    "\n",
    "pandas_df.to_csv(\"./omics_lc_word2vec.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "dx upload omics_lc_word2vec.csv --path /"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec PT Cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "combined_query = spark.sql(\"\"\"\n",
    "WITH EarliestCConds AS (\n",
    "    SELECT \n",
    "        c.eid,\n",
    "        MIN(TO_DATE(c.condition_start_date, 'dd/MM/yyyy')) as earliest_cond_date\n",
    "    FROM \n",
    "        omop_condition_occurrence c\n",
    "    WHERE \n",
    "        c.condition_source_value LIKE 'C%'\n",
    "    GROUP BY \n",
    "        c.eid\n",
    "),\n",
    "FilteredPatients AS (\n",
    "    SELECT \n",
    "        ecc.eid,\n",
    "        ecc.earliest_cond_date,\n",
    "        TO_DATE(p.p53_i0, 'yyyy-MM-dd') AS proteomics_date \n",
    "    FROM \n",
    "        EarliestCConds ecc\n",
    "    INNER JOIN \n",
    "        participant_0001 p ON ecc.eid = p.eid\n",
    "    WHERE \n",
    "        ecc.earliest_cond_date < TO_DATE(p.p53_i0, 'yyyy-MM-dd')\n",
    "        AND ecc.earliest_cond_date >= ADD_MONTHS(TO_DATE(p.p53_i0, 'yyyy-MM-dd'), -12)\n",
    ")\n",
    "\n",
    "SELECT \n",
    "    fp.eid, \n",
    "    c.concept_id, \n",
    "    c.record_date,\n",
    "    DATE_FORMAT(c.record_date, 'yyyy-MM-dd') as formatted_date\n",
    "FROM \n",
    "    FilteredPatients fp\n",
    "JOIN (\n",
    "    SELECT \n",
    "        o.eid, \n",
    "        o.condition_concept_id as concept_id, \n",
    "        TO_DATE(o.condition_start_date, 'dd/MM/yyyy') as record_date\n",
    "    FROM \n",
    "        omop_condition_occurrence o\n",
    "    UNION ALL\n",
    "    SELECT \n",
    "        o.eid, \n",
    "        o.procedure_concept_id as concept_id, \n",
    "        TO_DATE(o.procedure_date, 'dd/MM/yyyy') as record_date\n",
    "    FROM \n",
    "        omop_procedure_occurrence o\n",
    "    UNION ALL\n",
    "    SELECT \n",
    "        o.eid, \n",
    "        o.drug_concept_id as concept_id, \n",
    "        TO_DATE(o.drug_exposure_start_date, 'dd/MM/yyyy') as record_date\n",
    "    FROM \n",
    "        omop_drug_exposure o\n",
    "    UNION ALL\n",
    "    SELECT \n",
    "        o.eid, \n",
    "        o.observation_concept_id as concept_id, \n",
    "        TO_DATE(o.observation_date, 'dd/MM/yyyy') as record_date\n",
    "    FROM \n",
    "        omop_observation o\n",
    "    UNION ALL\n",
    "    SELECT \n",
    "        o.eid, \n",
    "        o.measurement_concept_id as concept_id, \n",
    "        TO_DATE(o.measurement_date, 'dd/MM/yyyy') as record_date\n",
    "    FROM \n",
    "        omop_measurement o\n",
    ") c ON fp.eid = c.eid\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Count the number of rows in the result\n",
    "row_count = combined_query.count()\n",
    "\n",
    "# Print the row count\n",
    "print(f\"Number of rows in the query result: {row_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "distinct_eids = combined_query.select(\"eid\").distinct()\n",
    "num_distinct_eids = distinct_eids.count()\n",
    "\n",
    "print(f\"Number of distinct eids: {num_distinct_eids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder.appName(\"Word2Vec Training\").getOrCreate()\n",
    "\n",
    "combined_query = combined_query.withColumn(\"concept_id\", combined_query[\"concept_id\"].cast(IntegerType()))\n",
    "\n",
    "# Group by 'eid' (person_id) and 'month_year'\n",
    "grouped_data = (combined_query.groupBy(\"eid\", \"formatted_date\")\n",
    "                .agg(F.collect_list(\"concept_id\").alias(\"concept_ids\")))\n",
    "\n",
    "# Define a UDF to convert integers to strings\n",
    "int_to_string_udf = udf(lambda x: [str(i) for i in x], ArrayType(StringType()))\n",
    "\n",
    "# Apply the UDF to the 'concept_ids' column\n",
    "word2Vec_data = grouped_data.withColumn(\"words\", int_to_string_udf(col(\"concept_ids\")))\n",
    "\n",
    "# Define the Word2Vec model\n",
    "print('started training')\n",
    "word2vec = Word2Vec(vectorSize=400, windowSize=100, minCount=5, inputCol=\"words\", outputCol=\"wordVectors\").setMaxIter(3)\n",
    "\n",
    "# Fit the model\n",
    "model = word2vec.fit(word2Vec_data)\n",
    "print('done training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "word_vectors = model.getVectors()\n",
    "\n",
    "pandas_df = word_vectors.toPandas()\n",
    "\n",
    "pandas_df.to_csv(\"./PT_lc_word2vec.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "dx upload PT_lc_word2vec.csv --path /"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downstream Processing for omics cohort only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "word_vectors = pd.read_csv('./PT_lc_word2vec.csv')\n",
    "word_vectors['vector'] = word_vectors['vector'].apply(ast.literal_eval)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "combined_query = spark.sql(\"\"\"\n",
    "WITH EarliestCConds AS (\n",
    "    SELECT \n",
    "        c.eid,\n",
    "        MIN(TO_DATE(c.condition_start_date, 'dd/MM/yyyy')) as earliest_cond_date\n",
    "    FROM \n",
    "        omop_condition_occurrence c\n",
    "    INNER JOIN \n",
    "        olink_instance_0_0001 o ON c.eid = o.eid\n",
    "    WHERE \n",
    "        c.condition_source_value LIKE 'C%'\n",
    "    GROUP BY \n",
    "        c.eid\n",
    "),\n",
    "FilteredPatients AS (\n",
    "    SELECT \n",
    "        ecc.eid,\n",
    "        ecc.earliest_cond_date,\n",
    "        TO_DATE(p.p53_i0, 'yyyy-MM-dd') AS proteomics_date \n",
    "    FROM \n",
    "        EarliestCConds ecc\n",
    "    INNER JOIN \n",
    "        participant_0001 p ON ecc.eid = p.eid\n",
    "    WHERE \n",
    "        ecc.earliest_cond_date < TO_DATE(p.p53_i0, 'yyyy-MM-dd')\n",
    "        AND ecc.earliest_cond_date >= ADD_MONTHS(TO_DATE(p.p53_i0, 'yyyy-MM-dd'), -12)\n",
    ")\n",
    "\n",
    "SELECT \n",
    "    fp.eid, \n",
    "    c.concept_id, \n",
    "    c.record_date,\n",
    "    DATE_FORMAT(c.record_date, 'yyyy-MM-dd') as formatted_date\n",
    "FROM \n",
    "    FilteredPatients fp\n",
    "JOIN (\n",
    "    SELECT \n",
    "        o.eid, \n",
    "        o.condition_concept_id as concept_id, \n",
    "        TO_DATE(o.condition_start_date, 'dd/MM/yyyy') as record_date\n",
    "    FROM \n",
    "        omop_condition_occurrence o\n",
    "    UNION ALL\n",
    "    SELECT \n",
    "        o.eid, \n",
    "        o.procedure_concept_id as concept_id, \n",
    "        TO_DATE(o.procedure_date, 'dd/MM/yyyy') as record_date\n",
    "    FROM \n",
    "        omop_procedure_occurrence o\n",
    "    UNION ALL\n",
    "    SELECT \n",
    "        o.eid, \n",
    "        o.drug_concept_id as concept_id, \n",
    "        TO_DATE(o.drug_exposure_start_date, 'dd/MM/yyyy') as record_date\n",
    "    FROM \n",
    "        omop_drug_exposure o\n",
    "    UNION ALL\n",
    "    SELECT \n",
    "        o.eid, \n",
    "        o.observation_concept_id as concept_id, \n",
    "        TO_DATE(o.observation_date, 'dd/MM/yyyy') as record_date\n",
    "    FROM \n",
    "        omop_observation o\n",
    "    UNION ALL\n",
    "    SELECT \n",
    "        o.eid, \n",
    "        o.measurement_concept_id as concept_id, \n",
    "        TO_DATE(o.measurement_date, 'dd/MM/yyyy') as record_date\n",
    "    FROM \n",
    "        omop_measurement o\n",
    ") c ON fp.eid = c.eid AND c.record_date <= fp.proteomics_date\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "combined_query_results = combined_query.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "pdf = pd.DataFrame(combined_query_results, columns=[field.name for field in combined_query.schema.fields])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "word_vectors['word'] = word_vectors['word'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pdf = pdf.merge(word_vectors, how='inner', left_on='concept_id', right_on='word').drop(['word','concept_id'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pdf.shape, pdf['eid'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "embeddings_df = pd.DataFrame(pdf['vector'].tolist(), index=pdf.index)\n",
    "embeddings_df.columns = [f'embedding_{i}' for i in range(embeddings_df.shape[1])]\n",
    "\n",
    "# Join the new DataFrame with the original DataFrame\n",
    "embedded_codes = pdf.join(embeddings_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embedded_codes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert 'record_date' to datetime format in Pandas\n",
    "embedded_codes['record_date'] = pd.to_datetime(embedded_codes['record_date'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "max_dates=32\n",
    "\n",
    "# 1. Sort the DataFrame\n",
    "embedded_codes = embedded_codes.sort_values(by=['eid', 'record_date'], ascending=[True, False])\n",
    "\n",
    "# 2. Rank within each 'eid' group\n",
    "embedded_codes['date_rank'] = embedded_codes.groupby('eid')['record_date'].rank(method='dense', ascending=False)\n",
    "\n",
    "# 3. Filter based on rank\n",
    "filtered_data_pd = embedded_codes[embedded_codes['date_rank'] <= max_dates]\n",
    "\n",
    "# 4. Define your aggregation expressions\n",
    "agg_funcs = {f'embedding_{i}': 'mean' for i in range(400)}\n",
    "\n",
    "# Apply aggregation with the defined expressions\n",
    "patient_day_embeddings_pd = filtered_data_pd.groupby(['eid', 'record_date']).agg(agg_funcs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "patient_day_embeddings_pd.reset_index().to_csv('./patient_day_embeddings_omics_PTword2vec_lc.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "dx upload patient_day_embeddings_omics_PTword2vec_lc.csv --path /"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
