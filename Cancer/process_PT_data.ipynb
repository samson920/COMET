{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import dxpy\n",
    "import dxdata\n",
    "import pandas as pd\n",
    "import random\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import Word2Vec\n",
    "from pyspark.sql.functions import col, udf, to_date, mean, expr\n",
    "from pyspark.sql.types import StringType, ArrayType, IntegerType, DoubleType\n",
    "from pyspark.ml.feature import Word2Vec\n",
    "from pyspark.sql.window import Window\n",
    "import ast\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"MyApp\") \\\n",
    "    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
    "    .config(\"spark.kryoserializer.buffer.max\", \"1g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# The SparkContext is accessible from the SparkSession as follows:\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dispensed_database_name = dxpy.find_one_data_object(classname=\"database\", name=\"app*\", folder=\"/\", name_mode=\"glob\", describe=True)[\"describe\"][\"name\"]\n",
    "dispensed_dataset_id = dxpy.find_one_data_object(typename=\"Dataset\", name=\"app*.dataset\", folder=\"/\", name_mode=\"glob\")[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"USE \" + dispensed_database_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#cancer patients with initial diagnosis at most 12 months before initial UKBB visit\n",
    "combined_query = spark.sql(\"\"\"\n",
    "WITH EarliestCConds AS (\n",
    "    SELECT \n",
    "        c.eid,\n",
    "        MIN(TO_DATE(c.condition_start_date, 'dd/MM/yyyy')) as earliest_cond_date\n",
    "    FROM \n",
    "        omop_condition_occurrence c\n",
    "    WHERE \n",
    "        c.condition_source_value LIKE 'C%'\n",
    "    GROUP BY \n",
    "        c.eid\n",
    "),\n",
    "FilteredPatients AS (\n",
    "    SELECT \n",
    "        ecc.eid,\n",
    "        ecc.earliest_cond_date,\n",
    "        TO_DATE(p.p53_i0, 'yyyy-MM-dd') AS proteomics_date \n",
    "    FROM \n",
    "        EarliestCConds ecc\n",
    "    INNER JOIN \n",
    "        participant_0001 p ON ecc.eid = p.eid\n",
    "    WHERE \n",
    "        ecc.earliest_cond_date <= ADD_MONTHS(TO_DATE(p.p53_i0, 'yyyy-MM-dd'), 60) AND\n",
    "        ecc.earliest_cond_date >= ADD_MONTHS(TO_DATE(p.p53_i0, 'yyyy-MM-dd'), -12)\n",
    ")\n",
    "\n",
    "SELECT \n",
    "    fp.eid, \n",
    "    c.concept_id, \n",
    "    c.record_date,\n",
    "    DATE_FORMAT(c.record_date, 'yyyy-MM-dd') as formatted_date\n",
    "FROM \n",
    "    FilteredPatients fp\n",
    "JOIN (\n",
    "    SELECT \n",
    "        o.eid, \n",
    "        o.condition_concept_id as concept_id, \n",
    "        TO_DATE(o.condition_start_date, 'dd/MM/yyyy') as record_date\n",
    "    FROM \n",
    "        omop_condition_occurrence o\n",
    "    UNION ALL\n",
    "    SELECT \n",
    "        o.eid, \n",
    "        o.procedure_concept_id as concept_id, \n",
    "        TO_DATE(o.procedure_date, 'dd/MM/yyyy') as record_date\n",
    "    FROM \n",
    "        omop_procedure_occurrence o\n",
    "    UNION ALL\n",
    "    SELECT \n",
    "        o.eid, \n",
    "        o.drug_concept_id as concept_id, \n",
    "        TO_DATE(o.drug_exposure_start_date, 'dd/MM/yyyy') as record_date\n",
    "    FROM \n",
    "        omop_drug_exposure o\n",
    "    UNION ALL\n",
    "    SELECT \n",
    "        o.eid, \n",
    "        o.observation_concept_id as concept_id, \n",
    "        TO_DATE(o.observation_date, 'dd/MM/yyyy') as record_date\n",
    "    FROM \n",
    "        omop_observation o\n",
    "    UNION ALL\n",
    "    SELECT \n",
    "        o.eid, \n",
    "        o.measurement_concept_id as concept_id, \n",
    "        TO_DATE(o.measurement_date, 'dd/MM/yyyy') as record_date\n",
    "    FROM \n",
    "        omop_measurement o\n",
    ") c ON fp.eid = c.eid AND c.record_date <= fp.earliest_cond_date\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "combined_query_results = combined_query.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "pdf = pd.DataFrame(combined_query_results, columns=[field.name for field in combined_query.schema.fields])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pdf['eid'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Convert 'record_date' to datetime format in Pandas\n",
    "pdf['record_date'] = pd.to_datetime(pdf['record_date'], format='%Y-%m-%d')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "max_dates=32\n",
    "\n",
    "# 1. Sort the DataFrame\n",
    "pdf = pdf.sort_values(by=['eid', 'record_date'], ascending=[True, False])\n",
    "\n",
    "# 2. Rank within each 'eid' group\n",
    "pdf['date_rank'] = pdf.groupby('eid')['record_date'].rank(method='dense', ascending=False)\n",
    "\n",
    "# 3. Filter based on rank\n",
    "filtered_pdf = pdf[pdf['date_rank'] <= max_dates]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "word_vectors = pd.read_csv('/mnt/project/PT_lc_word2vec.csv')\n",
    "word_vectors['vector'] = word_vectors['vector'].apply(ast.literal_eval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "word_vectors['word'] = word_vectors['word'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filtered_pdf = filtered_pdf.merge(word_vectors, how='inner', left_on='concept_id', right_on='word').drop(['word','concept_id'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filtered_pdf.shape, filtered_pdf['eid'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "indices = filtered_pdf.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "embeddings_array = np.array(filtered_pdf['vector'].tolist(), dtype=np.float64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embeddings_df = pd.DataFrame(embeddings_array, index=indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "embeddings_df.columns = [f'embedding_{i}' for i in range(embeddings_df.shape[1])]\n",
    "\n",
    "# Join the new DataFrame with the original DataFrame\n",
    "embedded_codes = filtered_pdf.join(embeddings_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# 4. Define your aggregation expressions\n",
    "agg_funcs = {f'embedding_{i}': 'mean' for i in range(400)}\n",
    "\n",
    "# Apply aggregation with the defined expressions\n",
    "patient_day_embeddings_pd = embedded_codes.groupby(['eid', 'record_date']).agg(agg_funcs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "patient_day_embeddings_pd.reset_index().to_csv('./patient_day_embeddings_PT_lc_LARGER.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "dx upload patient_day_embeddings_PT_lc_LARGER.csv --path /"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
